# LLM Orchestrator Service Environment Variables

# Server Configuration
PORT=3002
NODE_ENV=development

# CORS Configuration
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4-vision-preview
OPENAI_TIMEOUT=30000
OPENAI_MAX_RETRIES=3

# Circuit Breaker Configuration
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
CIRCUIT_BREAKER_TIMEOUT=30000
CIRCUIT_BREAKER_RECOVERY_TIME=60000

# Rate Limiting Configuration
RATE_LIMIT_WINDOW_MS=600000
RATE_LIMIT_MAX_REQUESTS=20
PROVIDER_RATE_LIMIT_MAX_REQUESTS=100

# Redis Configuration (for distributed rate limiting - optional)
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=

# Monitoring and Logging
LOG_LEVEL=info
ENABLE_REQUEST_LOGGING=true

# File Storage Configuration
STORAGE_PATH=../file-processor/storage
MAX_IMAGE_SIZE=20971520
SUPPORTED_IMAGE_FORMATS=jpg,jpeg,png,gif,webp

# Security Configuration
ENABLE_HELMET=true
ENABLE_CORS=true
REQUEST_SIZE_LIMIT=10mb

# Development/Testing
MOCK_OPENAI_RESPONSES=false
TEST_OPENAI_API_KEY=test-key